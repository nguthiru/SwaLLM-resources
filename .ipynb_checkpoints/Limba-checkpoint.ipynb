{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67539aad-8e7e-403c-ad0d-fbd4eb8f0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_split_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d3080-e795-4331-9979-68fa1e85fb78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55948230-4ecb-4336-bf92-37504a55f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_huggingface_dataset(dataset_name,*args,**kwargs):\n",
    "    dataset = load_dataset(dataset_name,**kwargs)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1f11e43-c0a2-498f-bc40-6a80b1c1f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_huggingface_dataset(\"mwitiderrick/swahili\",split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c2e0ad-eb77-4c04-9faf-9663f60f2898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_splits(dataset):\n",
    "  # Split the dataset into train, test and val\n",
    "\n",
    "  train_dataset = dataset.train_test_split(test_size=0.1, shuffle=True, seed=42)\n",
    "  test_val = train_dataset[\"test\"].train_test_split(\n",
    "      test_size=0.5, shuffle=True, seed=42\n",
    "  )\n",
    "  train_dataset = train_dataset[\"train\"]\n",
    "  test_dataset = test_val[\"test\"]\n",
    "  val_dataset = test_val[\"train\"]\n",
    "  return train_dataset,test_dataset,val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f19ccec1-97a7-455a-b376-a1a68efd0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, val_dataset = generate_dataset_splits(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81332eb8-c1ff-4c82-a145-46b6e32e1195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_non_text_symbols(text):\n",
    "  # remove texts that are not within that cannot be processed, e.g emojis, non-ascii symbols\n",
    "\n",
    "  # remove html tags\n",
    "  # soup = BeautifulSoup(text, \"html.parser\")\n",
    "  # text = soup.get_text()\n",
    "\n",
    "  # remove non-ascii symbols\n",
    "  text = re.sub(r'[^\\x00-\\x7F]+', '', text)\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c7d4966-cdfe-4bec-a400-e41aab61cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataset):\n",
    "\n",
    "  # clean the dataset object\n",
    "  dataset = dataset.map(lambda example: {\"text\": remove_non_text_symbols(example[\"text\"])})\n",
    "  dataset = dataset.filter(lambda example: len(example[\"text\"]) > 0)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42fd994e-4612-4bcc-bfb3-19d1d97fe3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = clean_dataset(train_dataset)\n",
    "test_dataset = clean_dataset(test_dataset)\n",
    "val_dataset = clean_dataset(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "814c494f-62d4-438d-b44d-0fa6598f5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "from tokenizers import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f757edc-a6d8-464d-ad42-f7fc13126ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(tokenizer, dataset):\n",
    "  # tokenize the dataset\n",
    "  dataset = dataset.map(lambda example: tokenizer(example[\"text\"],padding=True,max_length=256))\n",
    "  return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97444a43-fbad-4e99-b947-19e2741f07a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KiswahiliSilabiTokenizer(PreTrainedTokenizerFast):\n",
    "    def __init__(self, tokenizer,unk_token=\"[UNK]\",sos_token=\"[SOS]\",eos_token=\"[EOS]\",space_token=\"[SPACE]\",pad_token=\"[PAD]\", **kwargs):\n",
    "        super().__init__(tokenizer_object=tokenizer, **kwargs)\n",
    "        self._vocab = tokenizer.get_vocab()\n",
    "        self.unk_token = unk_token\n",
    "        self.sos_token = sos_token\n",
    "        self.eos_token = eos_token\n",
    "        self.space_token = space_token\n",
    "        self.pad_token = pad_token\n",
    "\n",
    "      # Add special tokens to vocab if they are not already present\n",
    "        if self.sos_token not in self._vocab:\n",
    "            self._vocab[self.sos_token] = len(self._vocab)\n",
    "        if self.eos_token not in self._vocab:\n",
    "            self._vocab[self.eos_token] = len(self._vocab)\n",
    "        if self.unk_token not in self._vocab:\n",
    "            self._vocab[self.unk_token] = len(self._vocab)\n",
    "        if self.space_token not in self._vocab:\n",
    "            self._vocab[self.space_token] = len(self._vocab)\n",
    "        if self.pad_token not in self._vocab:\n",
    "            self._vocab[self.pad_token] = len(self._vocab)\n",
    "\n",
    "    def __call__(self, text,**kwargs):\n",
    "        ids = self.convert_tokens_to_ids(self.tokenize(text,**kwargs))\n",
    "\n",
    "        return {\"input_ids\": ids}\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls, pretrained_model_name_or_path, **kwargs):\n",
    "        tokenizer = Tokenizer.from_file(f\"{pretrained_model_name_or_path}/tokenizer.json\")\n",
    "        return cls(tokenizer, **kwargs)\n",
    "\n",
    "    def _encode_with_byte_fallback(self, text):\n",
    "        tokens = []\n",
    "        i = 0\n",
    "        while i < len(text):\n",
    "            matched = False\n",
    "            # Try to match the longest syllable first\n",
    "            for j in range(len(text), i, -1):\n",
    "                syllable_candidate = text[i:j]\n",
    "                if syllable_candidate in self._vocab:\n",
    "                    tokens.append(syllable_candidate)\n",
    "                    i = j\n",
    "                    matched = True\n",
    "                    break\n",
    "            # If no syllable matched, fallback to byte encoding\n",
    "            if not matched:\n",
    "                if text[i] == \" \":\n",
    "                  tokens.append(self.space_token)\n",
    "                  i += 1\n",
    "                else:\n",
    "                  tokens.extend(self.unk_token)\n",
    "                  i += 1\n",
    "        return tokens\n",
    "\n",
    "    def tokenize(self, text,**kwargs):\n",
    "        handle_whitespace = kwargs.get(\"handle_whitespace\", True)\n",
    "        tokens = [self.sos_token]  # Start of sentence token\n",
    "        for word in text.split(\" \"):\n",
    "            tokens.extend(self._encode_with_byte_fallback(word))\n",
    "            if handle_whitespace:\n",
    "              tokens.extend(self._encode_with_byte_fallback(\" \"))\n",
    "        tokens.append(self.eos_token)  # End of sentence token\n",
    "\n",
    "        padding = kwargs.get(\"padding\", False)\n",
    "        if padding:\n",
    "            max_length = kwargs.get(\"max_length\", None)\n",
    "            if max_length is not None:\n",
    "                tokens = tokens[:max_length]\n",
    "                tokens.extend([self.pad_token] * (max_length - len(tokens)))\n",
    "            else:\n",
    "                raise ValueError(\"max_length must be specified if padding is True\")\n",
    "        return tokens\n",
    "\n",
    "    def tokens_to_sentence(self,tokens):\n",
    "      for token in tokens:\n",
    "        token = token.replace(\" \", \"\")\n",
    "      sentence = \"\".join(tokens)\n",
    "      sentence = sentence.replace(self.eos_token, \"\")\n",
    "      sentence = sentence.replace(self.sos_token, \"\")\n",
    "      sentence = sentence.replace(self.space_token,\" \")\n",
    "      return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f189851f-1012-40b0-981b-c0788b1d9c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "silabi_tokenizer = KiswahiliSilabiTokenizer.from_pretrained(\"./silabi_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d0c11ef-4351-4784-a5ff-3f3895fc205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_tokenized_dataset = tokenize(silabi_tokenizer, train_dataset)\n",
    "test_tokenized_dataset = tokenize(silabi_tokenizer, test_dataset)\n",
    "# val_tokenized_dataset = tokenize(silabi_tokenizer, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe34473f-5359-4699-b6f0-f4a6505e7153",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fc11b41-c12b-4571-8c56-e2b987644460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.mamba2.modeling_mamba2 import Mamba2Block\n",
    "from linear_attention_transformer import LinearAttentionTransformer\n",
    "from transformers.models.mamba2 import Mamba2Config, Mamba2ForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31141879-e8e2-4552-82e1-58363690181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "\n",
    "test_value = test_tokenized_dataset['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a77fcfce-b607-413c-bbb3-a9865bc6acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_array = np.array(test_value)\n",
    "input_tensor = torch.from_numpy(np_array).to(dtype=torch.long)\n",
    "input_tensor = input_tensor.unsqueeze(0)  # Shape becomes (1, sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699acb4e-e53b-4453-9353-8d77788fefb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f0f5545-92dc-407d-bc6b-b4ccebb925bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The fast path is not available because on of `(selective_state_update, causal_conv1d_fn, causal_conv1d_update)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n"
     ]
    }
   ],
   "source": [
    "mamba_config = Mamba2Config(vocab_size=silabi_tokenizer.vocab_size,hidden_size=512,num_heads=16)\n",
    "# hidden_size = dimension\n",
    "mamba_block = Mamba2Block(\n",
    "    config=mamba_config, layer_idx=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39d43e74-4b64-4cf2-852c-67cf9d4bf381",
   "metadata": {},
   "outputs": [],
   "source": [
    "mamba_embedding_dim = 512  # embedding dimension must match linformer dim\n",
    "vocab_size = silabi_tokenizer.vocab_size\n",
    "mamba_embedding_layer = torch.nn.Embedding(num_embeddings=silabi_tokenizer.vocab_size, embedding_dim=mamba_embedding_dim)\n",
    "mamba_embedded_tensor = mamba_embedding_layer(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68835ad2-edec-4003-8f25-c9f03e696bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 512])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mamba_embedded_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f38cdda-4932-4a97-a172-f7d2f00c6438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.2783, -1.0339, -0.9427,  ..., -0.5613, -0.8762, -2.3706],\n",
       "         [-0.6368, -2.1302, -0.2276,  ...,  1.2049, -1.0844, -0.2040],\n",
       "         [ 1.0469, -2.3309,  1.2093,  ...,  3.6927, -1.4960, -0.9574],\n",
       "         ...,\n",
       "         [ 1.2692,  0.0251,  0.2406,  ..., -0.1946,  0.1979,  1.2899],\n",
       "         [ 1.2692,  0.0251,  0.2406,  ..., -0.1946,  0.1979,  1.2899],\n",
       "         [ 1.2692,  0.0251,  0.2406,  ..., -0.1946,  0.1979,  1.2899]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mamba_block(mamba_embedded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e2327cb-55d4-48c4-b37d-18275c59028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (batch, sequence_length {256}) -> [embedding] -> (batch, sequence_length {256}. dimension {128}) -> [linformer] -> (batch, sequence_length {256}. dimension {128})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0e06041-14c8-4cbc-9812-b1a903d89e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "linformer = LinearAttentionTransformer(\n",
    "    dim = 512,\n",
    "    heads = 8,\n",
    "    depth = 1,\n",
    "    max_seq_len = 256,\n",
    "    n_local_attn_heads = 4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95524e78-2c81-44b1-b832-dbd62d1e7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512  # embedding dimension must match linformer dim\n",
    "vocab_size = silabi_tokenizer.vocab_size\n",
    "embedding_layer = torch.nn.Embedding(num_embeddings=silabi_tokenizer.vocab_size, embedding_dim=embedding_dim)\n",
    "embedded_tensor = embedding_layer(input_tensor)  # Shape: (batch_size, sequence_length, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "448c9b85-4f06-47eb-a0a1-9be71bf30d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f8b1aca-9c62-4eaf-aca3-c7bde75b7965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1979, -1.5463,  0.2702,  ...,  1.0276, -0.1961,  0.2674],\n",
       "         [ 1.5884, -0.2209,  0.0208,  ...,  1.3840, -0.6087,  0.4319],\n",
       "         [ 0.6247,  0.5986, -0.4655,  ...,  1.4478, -0.2209, -0.9150],\n",
       "         ...,\n",
       "         [ 1.6710,  0.5188,  2.0017,  ..., -2.3979, -0.8950, -0.6265],\n",
       "         [ 1.6710,  0.5188,  2.0017,  ..., -2.3979, -0.8950, -0.6265],\n",
       "         [ 1.6710,  0.5188,  2.0017,  ..., -2.3979, -0.8950, -0.6265]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linformer(embedded_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d489691-e415-40be-8140-a2719c0c1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class LinformerConfig:\n",
    "    dim: int\n",
    "    heads: int\n",
    "    depth: int\n",
    "    max_seq_len: int\n",
    "    n_local_attn_heads: int\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"dim\": self.dim,\n",
    "            \"heads\": self.heads,\n",
    "            \"max_seq_len\": self.max_seq_len,\n",
    "            \"n_local_attn_heads\": self.n_local_attn_heads,\n",
    "            \"depth\": self.depth\n",
    "        }\n",
    "@dataclass\n",
    "class MambaConfig:\n",
    "    hidden_size: int # this is also the dimension\n",
    "    num_heads: int \n",
    "\n",
    "\n",
    "    @property\n",
    "    def dim(self):\n",
    "        return self.hidden_size\n",
    "\n",
    "    def mamba2_config(self,vocab_size):\n",
    "        return Mamba2Config(vocab_size=vocab_size,hidden_size=self.hidden_size,num_heads=self.num_heads)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "45d6c17b-c7d0-43e4-94c1-6dc54b665c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MambaBlock(nn.Module):\n",
    "    def __init__(self,vocab_size, config: MambaConfig,layer_idx=0):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        #self.embedding = nn.Embedding(num_embeddings=self.vocab_size, embedding_dim=config.dim)\n",
    "        self.normalization = nn.modules.normalization.RMSNorm(config.dim)\n",
    "        self.mamba2_block = Mamba2Block(config = config.mamba2_config(self.vocab_size),layer_idx=layer_idx)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        #x = self.embedding(x)\n",
    "        x = self.normalization(x)\n",
    "        mamba_output = self.mamba2_block(x)\n",
    "        x = x + mamba_output\n",
    "        \n",
    "        x = self.normalization(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5851c3f0-d4a2-4c13-8e59-fbbb2269b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinformerBlock(nn.Module):\n",
    "    def __init__(self,vocab_size,config:LinformerConfig):\n",
    "        super().__init__()\n",
    "        #self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=config.dim)\n",
    "        self.normalization = nn.modules.normalization.RMSNorm(config.dim)\n",
    "        self.linformer = LinearAttentionTransformer(\n",
    "            **config.to_dict()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        #x = self.embedding(x)\n",
    "        x = self.normalization(x)\n",
    "        output = self.linformer(x)\n",
    "        x = output + x\n",
    "\n",
    "        x = self.normalization(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f95872d9-3852-4952-bbd2-9ad33f4ff357",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LimbaBlock(nn.Module):\n",
    "    def __init__(self,linformer_config,mamba_config,layer_idx=0,vocab_size=1000,dropout = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mamba_block = MambaBlock(vocab_size,mamba_config,layer_idx=layer_idx)\n",
    "        self.linformer_block = LinformerBlock(vocab_size,linformer_config)\n",
    "        \n",
    "        self.linformer_mamba_reshape = nn.Linear(linformer_config.dim, mamba_config.dim)\n",
    "        self.mamba_linformer_reshape = nn.Linear(mamba_config.dim, linformer_config.dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x -> (batch,seq_len)\n",
    "        x = self.mamba_block(x)\n",
    "\n",
    "        x = self.mamba_linformer_reshape(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.linformer_block(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.linformer_mamba_reshape(x)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        return x\n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "dc7a263e-2a58-464f-af4e-55278fe94a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linformer_config = LinformerConfig(dim = 256,\n",
    "    heads = 8,\n",
    "    depth = 1,\n",
    "    max_seq_len = 256,\n",
    "    n_local_attn_heads = 4)\n",
    "mamba_config = MambaConfig(\n",
    "    hidden_size = 512,\n",
    "    num_heads = 16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed75f92f-0c65-4041-8226-be661205160c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990bde17-c772-4fdc-97fc-96343ccc5ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd388c0-5a06-4460-afb4-d529250e8445",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "e7abd9cc-0ff9-45da-a562-2741ea5f2117",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Limba(nn.Module):\n",
    "    def __init__(self, linformer_config, mamba_config, vocab_size, num_layers=6,dropout=0.1):\n",
    "        super(Limba, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=mamba_config.dim)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                LimbaBlock(linformer_config, mamba_config, vocab_size) for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(mamba_config.dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "\n",
    "        self.output_layer = nn.Linear(mamba_config.dim, vocab_size)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass input through embedding layer\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        \n",
    "        x = self.layer_norm(x)\n",
    "        logits = self.output_layer(x)\n",
    "\n",
    "        return logits\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "1e42aa3d-d263-41a7-85aa-fc81ba167e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Limba(linformer_config,mamba_config, silabi_tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8e516dce-4383-4f7a-b726-239b38b33d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.8918,  0.1215, -1.0221,  ..., -0.1375,  0.6453,  0.2408],\n",
      "         [ 0.6800,  0.0238,  0.5443,  ...,  0.3798,  0.3497,  0.3220],\n",
      "         [-0.3338,  0.0462,  0.9040,  ...,  0.1092,  0.4037,  0.3869],\n",
      "         ...,\n",
      "         [-0.8182,  0.2585,  0.8561,  ...,  1.0838,  0.3018, -0.9353],\n",
      "         [-0.3339, -0.7124,  0.0153,  ..., -0.9043,  1.2537, -0.0372],\n",
      "         [-0.2685, -1.0179, -0.1490,  ...,  0.3481,  0.0739, -0.3264]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model(input_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "676c988a-245d-4192-9b98-b38ee8d1860a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type:depth-idx)                                                      Output Shape              Param #\n",
       "=============================================================================================================================\n",
       "Limba                                                                       [1, 256, 512]             --\n",
       "├─Embedding: 1-1                                                            [1, 256, 512]             338,944\n",
       "├─ModuleList: 1-2                                                           --                        --\n",
       "│    └─LimbaBlock: 2-1                                                      [1, 256, 512]             --\n",
       "│    │    └─MambaBlock: 3-1                                                 [1, 256, 512]             2,647,088\n",
       "│    │    └─Linear: 3-2                                                     [1, 256, 256]             131,328\n",
       "│    │    └─Dropout: 3-3                                                    [1, 256, 256]             --\n",
       "│    │    └─LinformerBlock: 3-4                                             [1, 256, 256]             789,248\n",
       "│    │    └─Dropout: 3-5                                                    [1, 256, 256]             --\n",
       "│    │    └─Linear: 3-6                                                     [1, 256, 512]             131,584\n",
       "│    └─LimbaBlock: 2-2                                                      [1, 256, 512]             --\n",
       "│    │    └─MambaBlock: 3-7                                                 [1, 256, 512]             2,647,088\n",
       "│    │    └─Linear: 3-8                                                     [1, 256, 256]             131,328\n",
       "│    │    └─Dropout: 3-9                                                    [1, 256, 256]             --\n",
       "│    │    └─LinformerBlock: 3-10                                            [1, 256, 256]             789,248\n",
       "│    │    └─Dropout: 3-11                                                   [1, 256, 256]             --\n",
       "│    │    └─Linear: 3-12                                                    [1, 256, 512]             131,584\n",
       "│    └─LimbaBlock: 2-3                                                      [1, 256, 512]             --\n",
       "│    │    └─MambaBlock: 3-13                                                [1, 256, 512]             2,647,088\n",
       "│    │    └─Linear: 3-14                                                    [1, 256, 256]             131,328\n",
       "│    │    └─Dropout: 3-15                                                   [1, 256, 256]             --\n",
       "│    │    └─LinformerBlock: 3-16                                            [1, 256, 256]             789,248\n",
       "│    │    └─Dropout: 3-17                                                   [1, 256, 256]             --\n",
       "│    │    └─Linear: 3-18                                                    [1, 256, 512]             131,584\n",
       "│    └─LimbaBlock: 2-4                                                      [1, 256, 512]             --\n",
       "│    │    └─MambaBlock: 3-19                                                [1, 256, 512]             2,647,088\n",
       "│    │    └─Linear: 3-20                                                    [1, 256, 256]             131,328\n",
       "│    │    └─Dropout: 3-21                                                   [1, 256, 256]             --\n",
       "│    │    └─LinformerBlock: 3-22                                            [1, 256, 256]             789,248\n",
       "│    │    └─Dropout: 3-23                                                   [1, 256, 256]             --\n",
       "│    │    └─Linear: 3-24                                                    [1, 256, 512]             131,584\n",
       "│    └─LimbaBlock: 2-5                                                      [1, 256, 512]             --\n",
       "│    │    └─MambaBlock: 3-25                                                [1, 256, 512]             2,647,088\n",
       "│    │    └─Linear: 3-26                                                    [1, 256, 256]             131,328\n",
       "│    │    └─Dropout: 3-27                                                   [1, 256, 256]             --\n",
       "│    │    └─LinformerBlock: 3-28                                            [1, 256, 256]             789,248\n",
       "│    │    └─Dropout: 3-29                                                   [1, 256, 256]             --\n",
       "│    │    └─Linear: 3-30                                                    [1, 256, 512]             131,584\n",
       "│    └─LimbaBlock: 2-6                                                      [1, 256, 512]             --\n",
       "│    │    └─MambaBlock: 3-31                                                [1, 256, 512]             2,647,088\n",
       "│    │    └─Linear: 3-32                                                    [1, 256, 256]             131,328\n",
       "│    │    └─Dropout: 3-33                                                   [1, 256, 256]             --\n",
       "│    │    └─LinformerBlock: 3-34                                            [1, 256, 256]             789,248\n",
       "│    │    └─Dropout: 3-35                                                   [1, 256, 256]             --\n",
       "│    │    └─Linear: 3-36                                                    [1, 256, 512]             131,584\n",
       "=============================================================================================================================\n",
       "Total params: 22,534,432\n",
       "Trainable params: 22,534,432\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 46.32\n",
       "=============================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 177.85\n",
       "Params size (MB): 90.14\n",
       "Estimated Total Size (MB): 267.99\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(limba, input_size=(1, 256),dtypes=[torch.long],device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3e1157-f0bc-4b23-bda5-022b82dea434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0cef46-6631-42c1-8136-e76ecbc15df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f3757d0b-2b41-47ac-93f2-d34d6f4dcf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, tokenized_dataset):\n",
    "        self.tokenized_dataset = tokenized_dataset\n",
    "        self.pad_token_id = silabi_tokenizer.pad_token_id\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_dataset)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.tokenized_dataset[idx]['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "b16643c1-adb5-499d-9e37-45c89e8912cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_tokenized = TokenizedDataset(train_tokenized_dataset)\n",
    "test_tokenized = TokenizedDataset(test_tokenized_dataset)\n",
    "#val_tokenized = TokenizedDataset(val_tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "9df1d35a-7fd7-4e93-9c42-e8994f9b8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  # Optional, for progress bar\n",
    "\n",
    "def train_model(model, train_loader, num_epochs=10, learning_rate=1e-4, device='cuda'):\n",
    "    # Move model to the specified device (GPU or CPU)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Initialize the optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Initialize the loss function\n",
    "    criterion = torch.nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding token (assumed to be 0)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Loop through the training data\n",
    "        for batch_idx, input_ids in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "            input_ids = input_ids.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass: get model output\n",
    "            output = model(input_ids)\n",
    "\n",
    "            # The output shape should be [batch_size, seq_len, vocab_size]\n",
    "            # For language modeling, the target is the input shifted by 1 position\n",
    "            target = input_ids[:, 1:].contiguous()  # Shift input for the target\n",
    "\n",
    "            # Pad the target to the same length as the output (if needed)\n",
    "            if target.size(1) < output.size(1):\n",
    "                target = F.pad(target, (0, output.size(1) - target.size(1)), value=0)\n",
    "\n",
    "            # Flatten the output and target tensors for CrossEntropyLoss\n",
    "            output = output.view(-1, output.size(-1))  # Flatten the output tensor\n",
    "            target = target.view(-1)  # Flatten the target tensor\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print the statistics for the current epoch\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "affe9e2d-a9f1-473a-a326-ed4e636fabe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mps_device = torch.device(\"mps\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "49156538-ae6c-4f31-84b9-25c62be72412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5fbb60b4-57c7-46d7-b751-e38b6ee091fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_tokenized,batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "de2ff45a-30ec-4931-bf22-67c19d359aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3:   0%|                         | 2/288338 [00:21<871:54:06, 10.89s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[300], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Assuming train_loader and val_loader are your data loaders\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m train_model(model, test_loader,num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[288], line 46\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, num_epochs, learning_rate, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Backpropagate the loss\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Update the weights\u001b[39;00m\n\u001b[1;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    583\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Assuming train_loader and val_loader are your data loaders\n",
    "train_model(model, test_loader,num_epochs=3, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad64be4-2611-4b5f-b8d1-0b061213c7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
